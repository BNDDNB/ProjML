>> history
    1 exit
    2 # Octave 4.0.3, Wed Nov 29 23:53:54 2017 EST <irixis@linux-fdcx>
    3 exit
    4 # Octave 4.0.3, Thu Nov 30 10:31:35 2017 EST <irixis@linux-fdcx>
    5 eye(4)]
    6 eye(4)
    7 pwd
    8 ls
    9 who
   10 exit
   11 # Octave 4.0.3, Thu Nov 30 11:53:45 2017 EST <irixis@linux-fdcx>
   12 A = eye(4)
   13 A[:,1:2]
   14 A(:,1:2);
   15 B = A(:,1:2)
   16 B =A(0:4,1:2)
   17 B =A(1:4,1:2)
   18 x = [1:4]
   19 size(x)
   20 x'
   21 size (X)
   22 size (x)
   23 x = x'
   24 size (x)
   25 A
   26 X
   27 x
   28 A.*x
   29 y = [2:5]
   30 y = y'
   31 xy
   32 x.*y
   33 sum(x.*y)
   34 exit
   35 # Octave 4.0.3, Thu Nov 30 22:06:26 2017 EST <irixis@linux-fdcx>
   36 # Octave 4.0.3, Fri Dec 01 10:29:55 2017 EST <irixis@linux-fdcx>
   37 # Octave 4.0.3, Fri Dec 01 10:33:34 2017 EST <irixis@linux-fdcx>
   38 who
   39 cd Projects/MLproj
   40 cd Projects/
   41 ls
   42 cd MLProj/
   43 ls
   44 cd MLex1
   45 ls
   46 cd ex1
   47 ls
   48 load ex1data1.txt
   49 who
   50 ls
   51 who
   52 ls
   53 x = ex1data1[:,1]
   54 x = ex1data1(:,1)
   55 y = ex1data1(:,2)
   56 m = length(y)
   57 plot(x,y,'rx','MarkerSize',10);
   58 ylabel('Profit in $10k');
   59 xlabel('Profit in 10k\'s');
   60 xlabel('Profit in 10k's');
   61 xlabel('Profit in 10k%s');
   62 xlabel('Profit in 10k%'s');
   63 xlabel('Profit in 10k');
   64 xlabel('Population in 10k');
   65 ones(m,1)
   66 X = [ones(m,1),data(:,1)]
   67 X = [ones(m,1),ex1data1(:,1)]
   68 history
   69 lpr history
   70 diary on
   71 history
>> theta = zeros(2,1)
theta =

   0
   0

>> iterations = 1500
iterations =  1500
>> alpha = 0.01
alpha =  0.010000
>> computeCost(X,y,theta)
J =  6222.1
ans =  6222.1
>> X
X =

    1.0000    6.1101

>> y
y =

   17.59200

>> y
y =

   17.59200

>> computeCost(X,y,theta)
ans =  32.073
>> submit()
== Submitting solutions | Linear Regression with Multiple Variables...
Login (email address): bonan.dong@outlook.com
Token: SEzLfxYxy8OICpGW
== 
==                                   Part Name |     Score | Feedback
==                                   --------- |     ----- | --------
==                            Warm-up Exercise |  10 /  10 | Nice work!
==           Computing Cost (for One Variable) |  40 /  40 | Nice work!
==         Gradient Descent (for One Variable) |   0 /  50 | 
==                       Feature Normalization |   0 /   0 | 
==     Computing Cost (for Multiple Variables) |   0 /   0 | 
==   Gradient Descent (for Multiple Variables) |   0 /   0 | 
==                            Normal Equations |   0 /   0 | 
==                                   --------------------------------
==                                             |  50 / 100 | 
== 
>> a = [1 2;3 4]
a =

   1   2
   3   4

>> sum(a)
ans =

   4   6

>> sum(a,2)
ans =

   3
   7

>> theta
theta =

   0
   0

>> theta = theta - alpha*(sum((X*theta - y).*X),2)/m;
parse error:

  syntax error

>>> theta = theta - alpha*(sum((X*theta - y).*X),2)/m;
                                                ^

>> a
a =

   1   2
   3   4

>> b = [2;4]
b =

   2
   4

>> b.*a
ans =

    2    4
   12   16

>> sum9(b.*a),2)
parse error:

  syntax error

>>> sum9(b.*a),2)
                ^

>> sum((b.*a),2)
ans =

    6
   28

>> theta = theta - alpha*(sum((X*theta - y).*X),2)/m;
parse error:

  syntax error

>>> theta = theta - alpha*(sum((X*theta - y).*X),2)/m;
                                                ^

>> theta = theta - alpha*(sum((X*theta - y).*X),2))/m;
parse error:

  syntax error

>>> theta = theta - alpha*(sum((X*theta - y).*X),2))/m;
                                                ^

>> theta
theta =

   0
   0

>> alpha*(sum((X*theta - y).*X),2))/m
parse error:

  syntax error

>>> alpha*(sum((X*theta - y).*X),2))/m
                                ^

>> alpha*(sum((X*theta - y).*X,2))/m
ans =

  -1.2895e-02

>> theta = theta - alpha*(sum((X*theta - y).*X,2))/m;
error: operator -: nonconformant arguments (op1 is 2x1, op2 is 97x1)
>> theta = theta - alpha*(sum(((X*theta - y).*X)',2))/m;
>> theta
theta =

   0.058391
   0.653288

>> theta = Zeros(2,1)
error: 'Zeros' undefined near line 1 column 9
>> theta = zeros(2,1)
theta =

   0
   0

>> theta = zeros(1,2)
theta =

   0   0

>> theta = zeros(2,1)
theta =

   0
   0

>> theta, hist = gradientDescent(X,y,theta, alpha, num_iters)
theta =

   0
   0

error: 'num_iters' undefined near line 1 column 49
error: evaluating argument list element number 5
>> theta, hist = gradientDescent(X,y,theta, alpha, iterations)
theta =

   0
   0

parse error near line 19 of file /home/irixis/Projects/MLProj/MLex1/ex1/gradientDescent.m

  syntax error

>>>     theta = theta - alpha*(sum(((X*theta - y).*X)',2)/m;
                                                          ^

>> theta, hist = gradientDescent(X,y,theta, alpha, iterations)
theta =

   0
   0

parse error near line 19 of file /home/irixis/Projects/MLProj/MLex1/ex1/gradientDescent.m

  syntax error

>>>     theta = theta - alpha*(sum(((X*theta - y).*X)' , 2)/m;
                                                            ^

>> theta = theta - alpha*(sum(((X*theta - y).*X)' , 2)/m


>> theta = theta - alpha*(sum(((X*theta - y).*X)' , 2)/m
'

>> theta
theta =

   0
   0

>> theta, hist = gradientDescent(X,y,theta, alpha, iterations)
theta =

   0
   0

hist =

  -3.6303
   1.1664

>> theta, hist = gradientDescent(X,y,theta, alpha, iterations);
theta =

   0
   0

>> theta
theta =

   0
   0

>> 
>> theta, hist = gradientDescent(X,y,theta, alpha, iterations);
  0.86495
 
